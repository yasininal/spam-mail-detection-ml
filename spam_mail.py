# ğŸ§© 1. KÃ¼tÃ¼phanelerin YÃ¼klenmesi

import numpy as np              # SayÄ±sal iÅŸlemler iÃ§in kullanÄ±lÄ±r (array, matematiksel hesaplamalar)
import pandas as pd             # Veri yÃ¼kleme, dÃ¼zenleme ve tablo iÅŸlemleri iÃ§in kullanÄ±lÄ±r
import matplotlib.pyplot as plt # GÃ¶rselleÅŸtirme iÃ§in kullanÄ±lÄ±r
import seaborn as sns           # GÃ¶rselleÅŸtirme iÃ§in kullanÄ±lÄ±r

from sklearn.model_selection import train_test_split          # Veriyi eÄŸitim ve test olarak ayÄ±rmak iÃ§in
from sklearn.feature_extraction.text import TfidfVectorizer   # Metin verisini sayÄ±sal Ã¶zelliklere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in
from sklearn.linear_model import LogisticRegression           # Lojistik regresyon sÄ±nÄ±flandÄ±rma modeli
from sklearn.metrics import accuracy_score , confusion_matrix # Modelin doÄŸruluk oranÄ±nÄ± Ã¶lÃ§mek iÃ§in accuracy_score ve gÃ¶rselleÅŸtirmek iÃ§in de confusion_matrix

print("TÃ¼m gerekli kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!")


# ğŸ“‚ 2. Veriyi YÃ¼kleme

# Veriyi csv(comma seperated values) dosyasÄ±ndan pandas dataframe'ine(satÄ±r ve sÃ¼tunlu durum) yÃ¼kleme iÅŸlemi

raw_mail_data = pd.read_csv('/content/mail_data.csv')

# Verimizdeki sÃ¼tunlarÄ±n incelenmesi

print(raw_mail_data.columns)

print(raw_mail_data)

# Dataframe'deki satÄ±r ve sÃ¼tun sayÄ±larÄ±

print(raw_mail_data.shape)

print("SatÄ±r sayÄ±sÄ±:", raw_mail_data.shape[0])
print("SÃ¼tun sayÄ±sÄ±:", raw_mail_data.shape[1])

# ğŸ”§ 3. Veri Ã–n HazÄ±rlÄ±ÄŸÄ±

# TF-IDF NaN ile Ã§alÄ±ÅŸmaz â†’ Hepsini boÅŸ string ile deÄŸiÅŸtiriyoruz.
mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')

# Tekrar eden mailleri temizliyoruz
mail_data.drop_duplicates(inplace=True)

# TemizlenmiÅŸ Dataframe'deki satÄ±r ve sÃ¼tun sayÄ±larÄ±

print(mail_data.shape)

print("\nSatÄ±r sayÄ±sÄ±:", mail_data.shape[0])
print("SÃ¼tun sayÄ±sÄ±:", mail_data.shape[1])


print("\nDuplicate Eden Mail SayÄ±sÄ±:", (raw_mail_data.shape[0] - mail_data.shape[0]))

# ğŸ” 4. Veri HakkÄ±nda Bilgi

# Dataframe'deki ilk 5 satÄ±rÄ± yazdÄ±rma iÅŸlemi

mail_data.head()

# ğŸ·ï¸ 5. Etiket DÃ¶nÃ¼ÅŸÃ¼mÃ¼

# Makine Ã¶ÄŸrenmesi sayÄ±sal veri ister â†’ spam = 1 , ham = 0

mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 1
mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 0

# ham  -  0

# spam  -  1

# ğŸ“Š ğŸ“Œ GÃ–RSEL: Spam / Ham DaÄŸÄ±lÄ±mÄ±

plt.figure(figsize=(6,4))
sns.countplot(data=mail_data, x="Category", palette="viridis")
plt.title("Spam ve Ham DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Kategori")
plt.ylabel("SayÄ±")
plt.show()

# ğŸ“¤ 6. Mesaj ve Etiket AyrÄ±mÄ±

# Verileri yazÄ± ve etikete gÃ¶re ayÄ±rma

X = mail_data['Message']

Y = mail_data['Category']

print(X)

print(Y)

# ğŸ“Š ğŸ“Œ GÃ–RSEL: Mesaj UzunluÄŸu DaÄŸÄ±lÄ±mÄ±

# Bu grafik, veri setimizin yapÄ±sÄ±nÄ± anlamamÄ±zÄ± saÄŸlar. BÃ¶ylece modelden Ã¶nce veri hakkÄ±nda sezgi kazanÄ±yoruz.


mail_data["length"] = mail_data["Message"].apply(lambda x: len(str(x)))

plt.figure(figsize=(10,5))
sns.histplot(mail_data["length"], bins=50, kde=True)
plt.title("Mesaj Uzunluk DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Mesaj UzunluÄŸu (karakter)")
plt.ylabel("Frekans")
plt.show()

# ğŸ“Š ğŸ“Œ GÃ–RSEL: Spam â€“ Ham Mesaj UzunluÄŸu KarÅŸÄ±laÅŸtÄ±rmasÄ±

plt.figure(figsize=(10,5))
sns.histplot(data=mail_data, x="length", hue="Category", bins=50, kde=True, palette="magma")
plt.title("Spam vs Ham Mesaj UzunluÄŸu")
plt.xlabel("Mesaj UzunluÄŸu (karakter)")
plt.ylabel("Frekans")
plt.show()

# âœ‚ï¸ 7. EÄŸitim â€“ Test AyrÄ±mÄ±

# Veri setini %80 eÄŸitim ve %20 test olarak ayÄ±rdÄ±k
# 'stratify=Y' parametresini kullanarak spam oranÄ±nÄ±n train ve test veri setlerinde aynÄ± oranda olmasÄ±nÄ± saÄŸladÄ±k
# BÃ¶yle modelimiz dengesiz olmuyor

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3, stratify=Y)

print(X.shape)
print(X_train.shape)
print(X_test.shape)

# DeÄŸerleri al
values = [
    X.shape[0],        # Toplam veri
    X_train.shape[0],  # EÄŸitim verisi
    X_test.shape[0]    # Test verisi
]

labels = ['X (Toplam Veri)', 'X_train (EÄŸitim)', 'X_test (Test)']

# Grafik oluÅŸturma
plt.figure(figsize=(8, 5))
plt.bar(labels, values)

plt.title("Veri DaÄŸÄ±lÄ±mÄ± (Toplam - EÄŸitim - Test)")
plt.xlabel("Veri Seti")
plt.ylabel("Adet")
plt.grid(axis='y', linestyle='--', alpha=0.6)

plt.show()


# ğŸ§  8. TF-IDF DÃ¶nÃ¼ÅŸÃ¼mÃ¼

# Metin verilerini Lojistik regresyona girdi olarak kullanÄ±labilecek Ã¶zellik vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rme
# 1ï¸âƒ£ min_df = 1
# Bir kelimenin modele alÄ±nmasÄ± iÃ§in en az 1 belgede geÃ§mesi gerektiÄŸini sÃ¶yler.
# Yani tÃ¼m kelimeleri dahil eder (filtre yok).

#2ï¸âƒ£ stop_words = 'english'
# Ä°ngilizce gereksiz kelimeleri kaldÄ±rÄ±r:
#   â€œthe, is, and, a, an, on, atâ€¦â€ gibi.
# Bu sayede model gereksiz kelimelerle uÄŸraÅŸmaz, daha iyi Ã¶ÄŸrenir.

#3ï¸âƒ£ lowercase = True
# Metnin tamamÄ±nÄ± kÃ¼Ã§Ã¼k harfe Ã§evirir.
# â€œHelloâ€ ve â€œhelloâ€ aynÄ± kelime olur â†’ daha tutarlÄ± bir model.

# TWEAKING DETAYI: 'ngram_range=(1, 2)' parametresini ekledik.
# Bu sayede model sadece "kazan" kelimesine deÄŸil, "Ã¶dÃ¼l kazan" ikilisine de bakÄ±yor.
# Bu yÃ¶ntem spam tespitini Ã§ok daha keskin (precise) hale getirir.

feature_extraction = TfidfVectorizer(
    min_df = 1,
    stop_words='english',
    lowercase= True,
    ngram_range=(1, 2)
    )

X_train_features = feature_extraction.fit_transform(X_train)  # Ã¶ÄŸren ve sayÄ±sala dÃ¶nÃ¼ÅŸtÃ¼r
X_test_features = feature_extraction.transform(X_test) #testi sadece dÃ¶nÃ¼ÅŸtÃ¼r Ã§Ã¼nkÃ¼ test setini de Ã¶ÄŸrenmek istemeyiz - overfitting

# Y_train ve Y_test deÄŸerlerini integer(tam sayÄ±)'ya dÃ¶nÃ¼ÅŸtÃ¼rme

Y_train = Y_train.astype('int')
Y_test = Y_test.astype('int')

print(X_train)

# (0, 2329) 0.387
#   â†’ 0. mailde 2329. kelimenin TF-IDF aÄŸÄ±rlÄ±ÄŸÄ±

print(X_train_features)

# 1. Spam Kelime Analizi KÄ±smÄ± (Veri Ã‡ekme ve Hesaplama)

# 1.1. Feature (Ã–zellik) Ä°simlerini AlalÄ±m
feature_names = feature_extraction.get_feature_names_out()

# 1.2. Y_train'i boolean bir diziye dÃ¶nÃ¼ÅŸtÃ¼relim (Spam: True, Ham: False)
is_spam_train = Y_train == 1

# 1.3. Sadece Spam Maillerin TF-IDF VektÃ¶rlerini Filtreleleyelim (Hata DÃ¼zeltmeli KÄ±sÄ±m)
# Seyrek matrisi indekslemek iÃ§in filtreyi .to_numpy() ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.
spam_features = X_train_features[is_spam_train.to_numpy()]

# 1.4. Her Ã–zelliÄŸin Toplam TF-IDF Skorunu HesaplayalÄ±m
spam_scores = np.array(spam_features.sum(axis=0)).flatten()

# 1.5. SkorlarÄ± ve Kelime Ä°simlerini Bir DataFrame'de BirleÅŸtirelim
df_scores = pd.DataFrame({'feature': feature_names, 'score': spam_scores})

# 1.6. En YÃ¼ksek SkorlarÄ± SÄ±ralayalÄ±m ve top_spam_words deÄŸiÅŸkenine atayalÄ±m (Ä°lk 20)
top_spam_words = df_scores.sort_values(by='score', ascending=False).head(20)
print("\n--- En Belirleyici Top 20 Kelime/N-gram ---")
print(top_spam_words)


# 2. GÃ¶rselleÅŸtirme KÄ±smÄ±

# Yatay grafikte en yÃ¼ksek skorun en Ã¼stte gÃ¶rÃ¼nmesi iÃ§in artan sÄ±ralama yapÄ±lÄ±r
top_spam_words_plot = top_spam_words.sort_values(by='score', ascending=True)

plt.figure(figsize=(10, 8))

# Yatay Ã§ubuklarÄ± Ã§izin
plt.barh(top_spam_words_plot['feature'], top_spam_words_plot['score'], color='firebrick')

# BaÅŸlÄ±klar ve etiketler ekleme
plt.title('Spam Maillerde En Belirleyici Kelimeler (GerÃ§ek TF-IDF SkorlarÄ±)', fontsize=14)
plt.xlabel('Toplam TF-IDF Skoru', fontsize=12)
plt.ylabel('Kelime / N-gram', fontsize=12)

# Etiketlerin kesilmemesi iÃ§in dÃ¼zeni ayarlama
plt.tight_layout()

# GÃ¶rseli kaydetme
plt.savefig('top_spam_words_barchart.png')

# ğŸ¤– 9. Model Kurma (Logistic Regression)

# Logistic Regression, bir veriyi iki sÄ±nÄ±ftan birine atamak iÃ§in kullanÄ±lan bir sÄ±nÄ±flandÄ±rma algoritmasÄ±dÄ±r.

model = LogisticRegression()

# Modeli eÄŸitim verisiyle eÄŸitme

model.fit(X_train_features, Y_train)

# ğŸ“Š 10. EÄŸitim & Test DoÄŸruluÄŸu

# EÄŸitim verisi iÃ§in tahmin yapma

prediction_on_training_data = model.predict(X_train_features)
accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)

print('Accuracy on training data : ', accuracy_on_training_data)

# Test Verisi iÃ§in tahmin yapma

prediction_on_test_data = model.predict(X_test_features)
accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)

print('Accuracy on test data : ', accuracy_on_test_data)

# ğŸ“Š ğŸ“Œ CONFUSION MATRIX GÃ–RSELÄ°

cm = confusion_matrix(Y_test, prediction_on_test_data)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu")
plt.title("Confusion Matrix")
plt.xlabel("Tahmin")
plt.ylabel("GerÃ§ek")
plt.show()

# âœ‰ï¸ 11. Yeni Bir Maili Test Etme

input_mail = ["Win a Free iPhone Now! Congratulations! You have been selected to receive a free iPhone. Click here to claim your prize."]

# String ifadeyi vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme
input_data_features = feature_extraction.transform(input_mail)

# Tahmin yapma iÅŸlemi
prediction = model.predict(input_data_features)
print(prediction)


if (prediction[0]==0):
  print('Ham mail')

else:
  print('Spam mail')


# Veri setinde olmayan Ã¶rnek spam mail test edebilirsiniz:
# Win a Free iPhone Now! Congratulations! You have been selected to receive a free iPhone. Click here to claim your prize.

# Veri setinde olmayan Ã¶rnek ham mail test edebilirsiniz:
# Class Notes. Hello, Iâ€™ve attached the notes from yesterdayâ€™s class. Let me know if you have any questions.

# ğŸ§± 12. Pipeline Ã–zet ÅemasÄ±

'''

1-          HAM / SPAM DATA

                   â†“

2-          Veri Temizleme

                   â†“

3-          TF-IDF DÃ¶nÃ¼ÅŸÃ¼mÃ¼

                   â†“

4-   Model EÄŸitimi (Logistic Regression)

                   â†“

5-          DoÄŸruluk Ã–lÃ§me

                   â†“

6-          Yeni Mail Tahmini


'''